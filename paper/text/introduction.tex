\section{Introduction}\label{sec:introduction}

As the world becomes more instrumented and interconnected, the amount of live
data generated from software and hardware sensors increases exponentially.
Data stream processing is a computational paradigm for on-the-fly analysis of
such streaming data at scale. Applications of streaming can be found in many
domains, such as financial markets~\cite{ref:app-finance},
telecommunications~\cite{ref:app-telco},
cyber-security~\cite{ref:app-cybersecurity}, and
health-care~\cite{ref:app-healthcare} to name a few.

A streaming application is typically represented as a graph of streams and
operators~\cite{ref:spl}, where operators are generic data manipulators and
streams connect operators to each other using FIFO semantics. In this model,
the data is analyzed as it streams through the set of operators forming the
graph. The key capability of streaming systems is their ability to process
high volume data sources with low latency. This is achieved by taking
advantage of various forms of parallelism that is naturally captured by the
streaming model of computation~\cite{ref:survey}, such as pipeline, task, and
data parallelism.

While streaming applications can capture various forms of parallelism, there
are several challenges in taking advantage of them in practice. First, the
operators, which are the building blocks of streaming applications, should be
easy to develop and preferably sequential in nature, saving the developers
from the complexities of parallelism. Second, we need a flexible scheduler
that can dynamically schedule operators to take advantage of pipeline, task,
and data parallelism in a transparent manner. Furthermore, the scheduler
should be configurable so that we can adjust the trade-off between low latency
and high throughput. Last, but not the least, the stream processing system
should be elastic in the sense that the level and kind of parallelism applied
can be adjusted depending on the resource and workload availability.

In this paper, we describe the design and implementation of \emph{C-Stream},
which is an elastic stream processing engine. C-Stream addresses all of the
aforementioned challenges.  First, in contrast to the widely adopted
event-based interface for developing stream processing operators, C-Stream
provides an interface wherein each operator has its own control loop and rely
on data availability APIs to decide when to perform its computations. This
model significantly simplifies development of multi-input port operators that
otherwise require complex synchronization. Furthermore, it enables
intra-operator optimizations such as batching. Second, C-Stream contains a
multi-threaded dynamic scheduler that manages the execution of the operators.
The scheduler, which is customizable via plug-ins, enables the execution of
the operators as co-routines, using any number of threads. The base scheduler
implements back-pressure, provides data availability APIs, and manages
preemption and termination handling. Scheduler plug-ins are used to implement
different scheduling policies that can prioritize latency or throughput. Last,
C-Stream provides elastic parallelization. It can dynamically adjust the
number of threads used to execute an application, and can also adjust the
number of replicas of data-parallel operators to resolve bottlenecks. For the
latter we focus on stateless operators, but the techniques also apply on
partitioned parallel operators\footnote{This requires state migration and
ordering support, which is not yet implemented in our prototype, but have been
implemented in other systems~\cite{ref:stream-parallel}}. Finally, we have
evaluated our system using a variety of topologies under varying operator
costs. The results show that C-Stream is scalable (with increasing number of
threads), highly customizable (in terms of scheduling goals), and can resolve
bottlenecks by dynamically adjusting the level of data parallelism used
(elasticity).
 
In summary, this paper makes the following contributions:
\begin{itemize}
\item We propose an operator development API that facilitates sequential
implementations, significantly simplifying development of multi-port
operators that otherwise require explicit synchronization.
\item We develop a flexible scheduler and accompanying runtime machinery for
executing operators that are implemented as co-routines, using multiple threads. 
\item We present techniques for elastic executing, including the adjustment of the
level of parallelism used and the number of operator replicas employed.
\item We provide a detailed evaluation of our system to showcase its efficacy.
\end{itemize}

The rest of this paper is organized as follows. Section~\ref{sec:related},
discusses related work. Section~\ref{sec:pmodel} overviews the programming
model and the operator development APIs used by C-Stream.
Section~\ref{sec:scheduler} describes the co-routine based runtime and the
multi-threaded scheduler. Section~\ref{sec:plugin} presents the custom
scheduler plug-ins we have developed. Section~\ref{sec:elasticity} explains
how Stream-C achieves elasticity. Section~\ref{sec:evaluation} presents our
experimental evaluation and Section~\ref{sec:conclusion} concludes the paper.


